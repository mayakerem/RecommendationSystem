{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMHGw6nXEc_P"
   },
   "source": [
    "# Recommendation System - Assignment 1\n",
    "\n",
    "Maya Kerem, Amit Huli\n",
    "\n",
    "Due Date: 13 / 12 / 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7PcxUPkE0M_",
    "outputId": "008bae67-a46e-47e8-91ac-b46737c08590"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from google.colab import drive \n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZrOjk6KUrl6",
    "outputId": "f4476631-419a-43ca-a2f3-88c75a2b54e2"
   },
   "outputs": [],
   "source": [
    "# !ls /content/drive/MyDrive/MSc\\ Data\\ Science/Recommendation\\ System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-UY_-TgE3f9"
   },
   "source": [
    "The goal of this homework is to let you understand the details of matrix factorization algorithm and practice recommender system training and evaluation. You should implement the matrix factorization algorithm by yourself using only basic Python libraries (such as numpy).\n",
    "\n",
    "**Submission:** Submission of the homework will be done via Moodle by uploading a zip file containing a Jupyter notbook and images. The homework needs to be entirely in English. The deadline for submission of Homework 1 is set to December 13, 2020 end of day Israel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6sG76ZnEE83U"
   },
   "outputs": [],
   "source": [
    "# rating_df = pd.read_csv(\"drive/MyDrive/MSc Data Science/Recommendation System/ratings.csv\") \n",
    "rating_df = pd.read_csv(\"ratings.csv\") \n",
    "# rating_df.head()\n",
    "# rating_df.min(axis =1)\n",
    "# rating_df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bn8d9SRsE9iE"
   },
   "source": [
    "**Question 1:** \n",
    "\n",
    "Data exploration (15 points)\n",
    "\n",
    "Download the MovieLens 100K rating dataset. Calculate the dataset sparsity, distribution of number of ratings as well as the average rating value per user\\item. Include additional exploration you find relevant to questions 2 and 3.\n",
    "Discuss your insights and possible challenges related to the prediction task described in question 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gHtT5CEjt3IT"
   },
   "outputs": [],
   "source": [
    "# Making the rating table\n",
    "row = rating_df['userId']\n",
    "col = rating_df['movieId']\n",
    "rating_mat = np.zeros((row.max()+1,col.max()+1))\n",
    "rating_mat[row,col] = rating_df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "_JkgThARRWMT",
    "outputId": "e9f51d7e-b55f-4d69-8c2c-83952838960c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 3.5, 0. , ..., 0. , 0. , 0. ],\n",
       "       ...,\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rating_mat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0fd2300fec9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrating_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rating_mat' is not defined"
     ]
    }
   ],
   "source": [
    "rating_mat.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZvHOPYDFA95"
   },
   "outputs": [],
   "source": [
    "# sparsity = 1 - number of ratings/(rating users* rateditems)\n",
    "sparsity = 1.0 - np.count_nonzero(rating_mat) / rating_mat.size\n",
    "# sparsity = count zero elements / total elements\n",
    "# distribution of number ratings\n",
    "# Average rating per user/item = total ratings/ rated users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_S98DIiFBXf"
   },
   "source": [
    "**Question 2:**\n",
    "\n",
    "Matrix factorization model implementation and evaluation (60 points)\n",
    "\n",
    "Split the data to 5 folds. Implement explicit matrix factorization algorithm to predict the rating a user will provide to an item and recommendation of top N items.\n",
    "Use the RMSE, MRR and NDCG metrics to evaluate your recommender system. For the MRR and NDCG metrics use cutoff values of 5 and 10. Produce a learning curve graph and a table which compares the results of the following algorithms:\n",
    "*  Different choices of the latent factor dimension, regularization, learning rate.\n",
    "*  Gradient Decent vs. ALS\n",
    "*  Bias only based model\n",
    "*  Simple popularity based model\n",
    "\n",
    "Describe your challenges and findings, including comparison between the algorithms as well as your recommendations for how to select the latent factor dimension, the contribution of regularization and pros\\cons of the different algorithms. In your comparison refer to the evaluation metrics, training and inference duration, learning convergence and additional aspects you find relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zcep_win50u2"
   },
   "outputs": [],
   "source": [
    "# step 0:\n",
    "# Create 5 folds. \n",
    "\n",
    "# Step1: \n",
    "# Initialize two random matrices a and b with dimensions m by k and k by n such (User/Item Matrix)\n",
    "# that when multiplied, their dimension matches the original matrix z (The rating matrix)\n",
    "# (that has dimensions m by n).\n",
    "# Ask asi if we need bias - if yes, we need to initialize the bias vectors (default, if not provided, make bias zeros)\n",
    "# k is part of the input\n",
    "\n",
    "# Step 2:\n",
    "# Multiply a by b to achieve an estimate for z. (Fill in the ratings matrix* - some missing values and wrong values\n",
    "# because we will calcualte the cost here)\n",
    "# if we need bias, we need to add the bias vectors her. \n",
    "\n",
    "# step 3:\n",
    "# Subtract z (our rating matrix) from y (calculated matrix) for the known values of z, \n",
    "# or some other loss function, to evaluate how far off the estimate is from the real matrix.\n",
    "\n",
    "# Step 4:\n",
    "# Use gradient descent/ OR ALS formulas to adjust each of the values in a and b in the right direction.\n",
    "# return value here is a and b (basically the new weights we got from user GD)\n",
    "\n",
    "# Step 5: \n",
    "# Repeat steps 2 to 4 repeatedly until the error has reached a reasonable value (Epsilon).\n",
    "\n",
    "# The end -> We get a and b that create a correct/optimized/after-learning ratings matrix that has no missing, it has the predicted values\n",
    "# By multiplying a by b, we now have an estimate for z that not only closely matches the known values of z, but also provides an estimate for the unknown values.\n",
    "\n",
    "# Step later:\n",
    "# do evaluation stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8fO-e-TFDBw"
   },
   "outputs": [],
   "source": [
    "# split to 5 folds\n",
    "# choose k for the users and items latent variables\n",
    "# createRatingMatrix(ratings_df) => numpy array of shape (N,M) |users| x |items| puts \n",
    "# matrixFactorization(R, k, regularization, learning rate, eps=0.01) => user matrix (Nxk), item matrix (Mxk), P (user bias matrix), O(item bias matrix)\n",
    "# using ALS/GD - ask for clarification regarding bias only based model - https://colab.research.google.com/gist/sagarmainkar/5cfa33898a303f895da5100472371d91/notebook.ipynb (https://towardsdatascience.com/gradient-descent-in-python-a0d07285742f)\n",
    "# learning user matrix, item matrix, user bias and item bias and outputs \n",
    "# predictUserRating(l_top, user_i, userMatrix, itemMatrix, biases) => top l items for user i\n",
    "# getRmse, getMrr, getNdcg => metric comparison https://gist.github.com/EthanRosenthal/a0816d8fea4394baf732 \n",
    "# plotting -> function that compares the above metrics\n",
    "# simple popularity model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nv-QDVafFDR3"
   },
   "source": [
    "**Question 3:**\n",
    "\n",
    "Matrix factorization – item similarity and model explainability (25 points)\n",
    "\n",
    "a) Suggest a method to find similarity between items. Demonstrate the approach on a set of 5 item pairs of your choice based on item representation by your best matrix factorization model. Leverage the items side information available in the dataset to demonstrate the effectiveness of the suggested approach.\n",
    "\n",
    "b) Select two latent dimensions of your matrix factorization model and try to estimate the latent ‘meaning’ of the learnt matrix factorization model. Demonstrate your estimation, using few items from the dataset and the items side information available in the dataset and\\or external information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zxko-ulPFFdp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RS - HW1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
